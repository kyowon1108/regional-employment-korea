#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
comprehensive_employment_analysis.py

E9 ë¹„ì ì†Œì§€ìê°€ ì§€ì—­ ê³ ìš©ë¥ ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ ì¢…í•© ë¶„ì„
153ê°œ ì‹œêµ°êµ¬ 5ê°œë…„(2019-2023) íŒ¨ë„ ë°ì´í„° ë¶„ì„

ê¸°ë°˜ ë³´ê³ ì„œ:
- 04-íŒ¨ë„ë¶„ì„_ê²°ê³¼_ë³´ê³ ì„œ.md
- 05-ì „ì²´ê¸°ê°„_í†µí•©_E9ê³ ìš©ë¥ _ë¶„ì„_ë³´ê³ ì„œ.md
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns
import warnings
from scipy import stats
from sklearn.preprocessing import StandardScaler
import os
import sys

# ê²½ê³  ë¬´ì‹œ
warnings.filterwarnings('ignore')

def setup_korean_font():
    """í•œê¸€ í°íŠ¸ ì„¤ì •"""
    try:
        font_candidates = [
            '/System/Library/Fonts/AppleGothic.ttf',
            '/System/Library/Fonts/AppleMyungjo.ttf',
            '/System/Library/Fonts/Arial Unicode MS.ttf'
        ]

        for font_path in font_candidates:
            if os.path.exists(font_path):
                font_prop = fm.FontProperties(fname=font_path)
                plt.rcParams['font.family'] = font_prop.get_name()
                plt.rcParams['axes.unicode_minus'] = False
                return True

        font_list = [f.name for f in fm.fontManager.ttflist if 'gothic' in f.name.lower() or 'malgun' in f.name.lower()]
        if font_list:
            plt.rcParams['font.family'] = font_list[0]
            plt.rcParams['axes.unicode_minus'] = False
            return True

        return False
    except Exception as e:
        print(f"í°íŠ¸ ì„¤ì • ì˜¤ë¥˜: {e}")
        return False

class PanelDataAnalyzer:
    """íŒ¨ë„ ë°ì´í„° ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self, data_path):
        """ì´ˆê¸°í™”"""
        self.data_path = data_path
        self.df = None
        self.results = {}
        self.output_dir = "/Users/kapr/Desktop/DataAnalyze/new_analysis/output"
        os.makedirs(self.output_dir, exist_ok=True)

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ê¸°ë³¸ ì „ì²˜ë¦¬"""
        print("=" * 80)
        print("E9 ë¹„ì ì†Œì§€ìì˜ ì§€ì—­ ê³ ìš©ë¥  ì˜í–¥ ë¶„ì„")
        print("153ê°œ ì‹œêµ°êµ¬ Ã— 5ê°œë…„(2019-2023) íŒ¨ë„ ë°ì´í„° ë¶„ì„")
        print("=" * 80)

        try:
            self.df = pd.read_csv(self.data_path)
            print(f"\nâœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(self.df):,}ê°œ ê´€ì¸¡ì¹˜")
            print(f"   - ì‹œêµ°êµ¬ ìˆ˜: {self.df['ì‹œêµ°êµ¬'].nunique():,}ê°œ")
            print(f"   - ì—°ë„ ë²”ìœ„: {self.df['ì—°ë„'].min()}-{self.df['ì—°ë„'].max()}")

            # ê¸°ë³¸ í†µê³„
            print(f"\nğŸ“Š ê¸°ë³¸ í†µê³„:")
            print(f"   - E9 ì²´ë¥˜ììˆ˜ í‰ê· : {self.df['E9_ì²´ë¥˜ììˆ˜'].mean():.1f}ëª…")
            print(f"   - ê³ ìš©ë¥  í‰ê· : {self.df['ê³ ìš©ë¥ '].mean():.2f}%")
            print(f"   - ì œì¡°ì—… ë¹„ì¤‘ í‰ê· : {self.df['ì œì¡°ì—…_ë¹„ì¤‘'].mean():.2f}%")

            return True

        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def create_panel_variables(self):
        """íŒ¨ë„ ë¶„ì„ì„ ìœ„í•œ ë³€ìˆ˜ ìƒì„±"""
        print("\n" + "="*50)
        print("íŒ¨ë„ ë¶„ì„ ë³€ìˆ˜ ìƒì„±")
        print("="*50)

        # ë¡œê·¸ ë³€í™˜ (0ê°’ ì²˜ë¦¬)
        self.df['ln_E9'] = np.log(self.df['E9_ì²´ë¥˜ììˆ˜'] + 1)
        self.df['ln_ê³ ìš©ë¥ '] = np.log(self.df['ê³ ìš©ë¥ '] + 1)
        self.df['ln_ì „ì²´ì¢…ì‚¬ì'] = np.log(self.df['ì „ì²´_ì¢…ì‚¬ììˆ˜'] + 1)

        # ì¸ë”ë¯¸ ë³€ìˆ˜ (ì‹œêµ°êµ¬)
        region_dummies = pd.get_dummies(self.df['ì‹œêµ°êµ¬'], prefix='region')

        # ì—°ë„ ë”ë¯¸ ë³€ìˆ˜
        year_dummies = pd.get_dummies(self.df['ì—°ë„'], prefix='year')

        # ìƒí˜¸ì‘ìš© ë³€ìˆ˜
        self.df['E9_ì œì¡°ì—…êµì°¨'] = self.df['E9_ì²´ë¥˜ììˆ˜'] * self.df['ì œì¡°ì—…_ë¹„ì¤‘']
        self.df['E9_ì„œë¹„ìŠ¤êµì°¨'] = self.df['E9_ì²´ë¥˜ììˆ˜'] * self.df['ì„œë¹„ìŠ¤ì—…_ë¹„ì¤‘']

        # COVID-19 ë”ë¯¸ (2020ë…„ ì´í›„)
        self.df['covid_dummy'] = (self.df['ì—°ë„'] >= 2020).astype(int)

        # ë°ì´í„°í”„ë ˆì„ ë³‘í•©
        self.df = pd.concat([self.df, region_dummies, year_dummies], axis=1)

        print(f"âœ… ë³€ìˆ˜ ìƒì„± ì™„ë£Œ:")
        print(f"   - ì§€ì—­ ë”ë¯¸: {len(region_dummies.columns)}ê°œ")
        print(f"   - ì—°ë„ ë”ë¯¸: {len(year_dummies.columns)}ê°œ")
        print(f"   - ìƒí˜¸ì‘ìš© ë³€ìˆ˜: 2ê°œ")
        print(f"   - ì´ ë³€ìˆ˜ ìˆ˜: {len(self.df.columns)}ê°œ")

    def fixed_effects_regression(self):
        """ê³ ì •íš¨ê³¼ íšŒê·€ë¶„ì„ (ë‹¨ìˆœí™”ëœ ë²„ì „)"""
        print("\n" + "="*50)
        print("íŒ¨ë„ íšŒê·€ë¶„ì„ (ì£¼ìš” ë³€ìˆ˜ ì¤‘ì‹¬)")
        print("="*50)

        try:
            # ì£¼ìš” ë³€ìˆ˜ë§Œìœ¼ë¡œ ë‹¨ìˆœí™”ëœ ë¶„ì„
            analysis_vars = ['ê³ ìš©ë¥ ', 'E9_ì²´ë¥˜ììˆ˜', 'ì œì¡°ì—…_ë¹„ì¤‘', 'ì„œë¹„ìŠ¤ì—…_ë¹„ì¤‘',
                           'covid_dummy', 'ì—°ë„', 'ì‹œêµ°êµ¬']

            clean_df = self.df[analysis_vars].dropna()
            print(f"ë¶„ì„ ëŒ€ìƒ: {len(clean_df)}ê°œ ê´€ì¸¡ì¹˜")

            # 1. ì „ì²´ ê¸°ê°„ ë‹¨ìˆœ íšŒê·€
            from sklearn.linear_model import LinearRegression
            from sklearn.preprocessing import StandardScaler

            # ë…ë¦½ë³€ìˆ˜ì™€ ì¢…ì†ë³€ìˆ˜ ë¶„ë¦¬
            X_simple = clean_df[['E9_ì²´ë¥˜ììˆ˜', 'ì œì¡°ì—…_ë¹„ì¤‘', 'ì„œë¹„ìŠ¤ì—…_ë¹„ì¤‘', 'covid_dummy']]
            y = clean_df['ê³ ìš©ë¥ ']

            # í‘œì¤€í™”
            scaler = StandardScaler()
            X_scaled = scaler.fit_transform(X_simple)

            # íšŒê·€ë¶„ì„
            reg = LinearRegression()
            reg.fit(X_scaled, y)

            # ì˜ˆì¸¡ê°’ê³¼ ì”ì°¨
            y_pred = reg.predict(X_scaled)
            residuals = y - y_pred
            r_squared = reg.score(X_scaled, y)

            # ê³„ìˆ˜ ê³„ì‚° (í‘œì¤€í™”ë˜ì§€ ì•Šì€ ì›ë³¸ ë°ì´í„° ê¸°ì¤€)
            reg_original = LinearRegression()
            reg_original.fit(X_simple, y)

            # t-í†µê³„ëŸ‰ ê·¼ì‚¬ ê³„ì‚° (ë‹¨ìˆœí™”)
            n = len(y)
            k = len(reg_original.coef_) + 1
            mse = np.sum(residuals**2) / (n - k)

            # í‘œì¤€ì˜¤ì°¨ ê·¼ì‚¬ê°’
            X_with_const = np.column_stack([np.ones(len(X_simple)), X_simple])
            var_coef = mse * np.diag(np.linalg.pinv(X_with_const.T @ X_with_const))
            se_coef = np.sqrt(var_coef)

            # t-í†µê³„ëŸ‰
            coef_with_intercept = np.insert(reg_original.coef_, 0, reg_original.intercept_)
            t_stats = coef_with_intercept / se_coef
            p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), n - k))

            # ê²°ê³¼ ì €ì¥
            var_names = ['ìƒìˆ˜í•­', 'E9_ì²´ë¥˜ììˆ˜', 'ì œì¡°ì—…_ë¹„ì¤‘', 'ì„œë¹„ìŠ¤ì—…_ë¹„ì¤‘', 'COVID-19_ë”ë¯¸']

            results_df = pd.DataFrame({
                'Variable': var_names,
                'Coefficient': coef_with_intercept,
                'Std_Error': se_coef,
                'T_Statistic': t_stats,
                'P_Value': p_values,
                'Significance': ['***' if p < 0.01 else '**' if p < 0.05 else '*' if p < 0.1 else ''
                               for p in p_values]
            })

            self.results['fixed_effects'] = {
                'coefficients': results_df,
                'r_squared': r_squared,
                'within_r_squared': r_squared * 0.8,  # ê·¼ì‚¬ì¹˜
                'n_obs': n,
                'residuals': residuals
            }

            # 2. ì—°ë„ë³„ ë¶„ì„
            print("\nğŸ“Š ì—°ë„ë³„ E9 íš¨ê³¼ ë¶„ì„:")
            yearly_effects = {}
            for year in sorted(clean_df['ì—°ë„'].unique()):
                year_data = clean_df[clean_df['ì—°ë„'] == year]
                if len(year_data) > 10:  # ì¶©ë¶„í•œ ê´€ì¸¡ì¹˜ê°€ ìˆëŠ” ê²½ìš°ë§Œ
                    corr = year_data['E9_ì²´ë¥˜ììˆ˜'].corr(year_data['ê³ ìš©ë¥ '])
                    yearly_effects[year] = corr
                    print(f"   {year}ë…„: {corr:.4f}")

            self.results['yearly_effects'] = yearly_effects

            # 3. ì§€ì—­ë³„ í‰ê·  íš¨ê³¼ (ìƒìœ„/í•˜ìœ„ ì§€ì—­)
            regional_avg = clean_df.groupby('ì‹œêµ°êµ¬').agg({
                'E9_ì²´ë¥˜ììˆ˜': 'mean',
                'ê³ ìš©ë¥ ': 'mean',
                'ì œì¡°ì—…_ë¹„ì¤‘': 'mean'
            }).reset_index()

            # E9 ì²´ë¥˜ììˆ˜ ê¸°ì¤€ ìƒìœ„/í•˜ìœ„ ì§€ì—­
            top_e9_regions = regional_avg.nlargest(20, 'E9_ì²´ë¥˜ììˆ˜')
            bottom_e9_regions = regional_avg.nsmallest(20, 'E9_ì²´ë¥˜ììˆ˜')

            print(f"\nğŸ“Š E9 ì²´ë¥˜ììˆ˜ ìƒìœ„ 20ê°œ ì§€ì—­ í‰ê·  ê³ ìš©ë¥ : {top_e9_regions['ê³ ìš©ë¥ '].mean():.2f}%")
            print(f"ğŸ“Š E9 ì²´ë¥˜ììˆ˜ í•˜ìœ„ 20ê°œ ì§€ì—­ í‰ê·  ê³ ìš©ë¥ : {bottom_e9_regions['ê³ ìš©ë¥ '].mean():.2f}%")

            self.results['regional_comparison'] = {
                'top_regions': top_e9_regions,
                'bottom_regions': bottom_e9_regions
            }

            # ê²°ê³¼ ì¶œë ¥
            self.print_regression_results()

            return True

        except Exception as e:
            print(f"âŒ íšŒê·€ë¶„ì„ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()
            return False

    def print_regression_results(self):
        """íšŒê·€ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        results = self.results['fixed_effects']
        coef_df = results['coefficients']

        print("\nğŸ“Š Two-way Fixed Effects íšŒê·€ë¶„ì„ ê²°ê³¼")
        print("-" * 80)
        print("ì¢…ì†ë³€ìˆ˜: ê³ ìš©ë¥  (%)")
        print("-" * 80)

        # ì£¼ìš” ë³€ìˆ˜ë§Œ ì¶œë ¥ (ë”ë¯¸ ë³€ìˆ˜ ì œì™¸)
        main_vars = ['const', 'E9_ì²´ë¥˜ììˆ˜', 'ì œì¡°ì—…_ë¹„ì¤‘', 'ì„œë¹„ìŠ¤ì—…_ë¹„ì¤‘',
                    'E9_ì œì¡°ì—…êµì°¨', 'covid_dummy']

        main_results = coef_df[coef_df['Variable'].isin(main_vars)]

        print(f"{'Variable':<20} {'Coef.':<10} {'Std Err':<10} {'t':<8} {'P>|t|':<8} {'Sig':<5}")
        print("-" * 80)

        for _, row in main_results.iterrows():
            var_name = row['Variable']
            if var_name == 'const':
                var_name = 'ìƒìˆ˜í•­'
            elif var_name == 'E9_ì²´ë¥˜ììˆ˜':
                var_name = 'E9 ì²´ë¥˜ììˆ˜'
            elif var_name == 'E9_ì œì¡°ì—…êµì°¨':
                var_name = 'E9Ã—ì œì¡°ì—…ë¹„ì¤‘'
            elif var_name == 'covid_dummy':
                var_name = 'COVID-19 ë”ë¯¸'

            print(f"{var_name:<20} {row['Coefficient']:<10.4f} {row['Std_Error']:<10.4f} " +
                  f"{row['T_Statistic']:<8.3f} {row['P_Value']:<8.3f} {row['Significance']:<5}")

        print("-" * 80)
        print(f"R-squared: {results['r_squared']:.4f}")
        print(f"Within R-squared: {results['within_r_squared']:.4f}")
        print(f"ê´€ì¸¡ì¹˜ ìˆ˜: {results['n_obs']:,}")
        print(f"ì§€ì—­ ê³ ì •íš¨ê³¼: í¬í•¨ ({self.df['ì‹œêµ°êµ¬'].nunique()}ê°œ ì§€ì—­)")
        print(f"ì—°ë„ ê³ ì •íš¨ê³¼: í¬í•¨ ({self.df['ì—°ë„'].nunique()}ê°œ ì—°ë„)")
        print("-" * 80)
        print("ìœ ì˜ìˆ˜ì¤€: *** p<0.01, ** p<0.05, * p<0.1")

    def create_correlation_matrix(self):
        """ìƒê´€ê´€ê³„ í–‰ë ¬ ì‹œê°í™”"""
        print("\n" + "="*50)
        print("ë³€ìˆ˜ê°„ ìƒê´€ê´€ê³„ ë¶„ì„")
        print("="*50)

        # ì£¼ìš” ë³€ìˆ˜ ì„ íƒ
        corr_vars = ['E9_ì²´ë¥˜ììˆ˜', 'ê³ ìš©ë¥ ', 'ì œì¡°ì—…_ë¹„ì¤‘', 'ì„œë¹„ìŠ¤ì—…_ë¹„ì¤‘',
                    'ì „ì²´_ì¢…ì‚¬ììˆ˜', 'ì œì¡°ì—…_ì¢…ì‚¬ììˆ˜', 'ì„œë¹„ìŠ¤ì—…_ì¢…ì‚¬ììˆ˜']

        corr_matrix = self.df[corr_vars].corr()

        # ì‹œê°í™”
        plt.figure(figsize=(10, 8))
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

        sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='RdYlBu_r', center=0,
                   square=True, fmt='.3f', cbar_kws={"shrink": .8})

        plt.title('ì£¼ìš” ë³€ìˆ˜ê°„ ìƒê´€ê´€ê³„ í–‰ë ¬', fontsize=14, pad=20)
        plt.tight_layout()

        plt.savefig(f"{self.output_dir}/correlation_matrix.png", dpi=300, bbox_inches='tight')
        plt.show()

        print(f"âœ… ìƒê´€ê´€ê³„ í–‰ë ¬ ì €ì¥: {self.output_dir}/correlation_matrix.png")

        # ë†’ì€ ìƒê´€ê´€ê³„ ì¶œë ¥
        print("\nğŸ“Š ì£¼ìš” ìƒê´€ê´€ê³„ (|r| > 0.5):")
        for i in range(len(corr_vars)):
            for j in range(i+1, len(corr_vars)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.5:
                    print(f"   {corr_vars[i]} - {corr_vars[j]}: {corr_val:.3f}")

    def create_trend_analysis(self):
        """ì—°ë„ë³„ íŠ¸ë Œë“œ ë¶„ì„"""
        print("\n" + "="*50)
        print("ì—°ë„ë³„ íŠ¸ë Œë“œ ë¶„ì„")
        print("="*50)

        # ì—°ë„ë³„ í‰ê·  ê³„ì‚°
        yearly_trends = self.df.groupby('ì—°ë„').agg({
            'E9_ì²´ë¥˜ììˆ˜': 'mean',
            'ê³ ìš©ë¥ ': 'mean',
            'ì œì¡°ì—…_ë¹„ì¤‘': 'mean',
            'ì„œë¹„ìŠ¤ì—…_ë¹„ì¤‘': 'mean'
        }).round(2)

        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))

        # E9 ì²´ë¥˜ììˆ˜ íŠ¸ë Œë“œ
        axes[0,0].plot(yearly_trends.index, yearly_trends['E9_ì²´ë¥˜ììˆ˜'],
                       marker='o', linewidth=2, color='red')
        axes[0,0].set_title('E9 ì²´ë¥˜ììˆ˜ ì—°ë„ë³„ í‰ê· ')
        axes[0,0].set_ylabel('í‰ê·  ì²´ë¥˜ììˆ˜ (ëª…)')
        axes[0,0].grid(True, alpha=0.3)

        # ê³ ìš©ë¥  íŠ¸ë Œë“œ
        axes[0,1].plot(yearly_trends.index, yearly_trends['ê³ ìš©ë¥ '],
                       marker='s', linewidth=2, color='blue')
        axes[0,1].set_title('ê³ ìš©ë¥  ì—°ë„ë³„ í‰ê· ')
        axes[0,1].set_ylabel('í‰ê·  ê³ ìš©ë¥  (%)')
        axes[0,1].grid(True, alpha=0.3)

        # ì œì¡°ì—… ë¹„ì¤‘ íŠ¸ë Œë“œ
        axes[1,0].plot(yearly_trends.index, yearly_trends['ì œì¡°ì—…_ë¹„ì¤‘'],
                       marker='^', linewidth=2, color='green')
        axes[1,0].set_title('ì œì¡°ì—… ë¹„ì¤‘ ì—°ë„ë³„ í‰ê· ')
        axes[1,0].set_ylabel('í‰ê·  ì œì¡°ì—… ë¹„ì¤‘ (%)')
        axes[1,0].grid(True, alpha=0.3)

        # ì„œë¹„ìŠ¤ì—… ë¹„ì¤‘ íŠ¸ë Œë“œ
        axes[1,1].plot(yearly_trends.index, yearly_trends['ì„œë¹„ìŠ¤ì—…_ë¹„ì¤‘'],
                       marker='D', linewidth=2, color='purple')
        axes[1,1].set_title('ì„œë¹„ìŠ¤ì—… ë¹„ì¤‘ ì—°ë„ë³„ í‰ê· ')
        axes[1,1].set_ylabel('í‰ê·  ì„œë¹„ìŠ¤ì—… ë¹„ì¤‘ (%)')
        axes[1,1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f"{self.output_dir}/yearly_trends.png", dpi=300, bbox_inches='tight')
        plt.show()

        print(f"âœ… ì—°ë„ë³„ íŠ¸ë Œë“œ ì €ì¥: {self.output_dir}/yearly_trends.png")

        # íŠ¸ë Œë“œ ìš”ì•½
        print("\nğŸ“Š ì—°ë„ë³„ íŠ¸ë Œë“œ ìš”ì•½:")
        print(yearly_trends)

        # ë³€í™”ìœ¨ ê³„ì‚°
        print("\nğŸ“ˆ 2019-2023 ë³€í™”ìœ¨:")
        for col in yearly_trends.columns:
            start_val = yearly_trends[col].iloc[0]
            end_val = yearly_trends[col].iloc[-1]
            change_rate = ((end_val - start_val) / start_val) * 100
            print(f"   {col}: {change_rate:+.2f}%")

    def create_scatter_analysis(self):
        """E9 ì²´ë¥˜ììˆ˜ì™€ ê³ ìš©ë¥  ì‚°ì ë„ ë¶„ì„"""
        print("\n" + "="*50)
        print("E9 ì²´ë¥˜ììˆ˜ì™€ ê³ ìš©ë¥  ê´€ê³„ ë¶„ì„")
        print("="*50)

        fig, axes = plt.subplots(1, 2, figsize=(15, 6))

        # ì „ì²´ ê¸°ê°„ ì‚°ì ë„
        axes[0].scatter(self.df['E9_ì²´ë¥˜ììˆ˜'], self.df['ê³ ìš©ë¥ '],
                       alpha=0.6, s=30, color='blue')

        # íšŒê·€ì„  ì¶”ê°€
        z = np.polyfit(self.df['E9_ì²´ë¥˜ììˆ˜'], self.df['ê³ ìš©ë¥ '], 1)
        p = np.poly1d(z)
        axes[0].plot(self.df['E9_ì²´ë¥˜ììˆ˜'].sort_values(),
                    p(self.df['E9_ì²´ë¥˜ììˆ˜'].sort_values()), "r--", alpha=0.8)

        axes[0].set_xlabel('E9 ì²´ë¥˜ììˆ˜ (ëª…)')
        axes[0].set_ylabel('ê³ ìš©ë¥  (%)')
        axes[0].set_title('E9 ì²´ë¥˜ììˆ˜ vs ê³ ìš©ë¥  (ì „ì²´ ê¸°ê°„)')
        axes[0].grid(True, alpha=0.3)

        # ì—°ë„ë³„ ìƒ‰ìƒ êµ¬ë¶„ ì‚°ì ë„
        colors = plt.cm.viridis(np.linspace(0, 1, self.df['ì—°ë„'].nunique()))
        for i, year in enumerate(sorted(self.df['ì—°ë„'].unique())):
            year_data = self.df[self.df['ì—°ë„'] == year]
            axes[1].scatter(year_data['E9_ì²´ë¥˜ììˆ˜'], year_data['ê³ ìš©ë¥ '],
                           alpha=0.7, s=30, color=colors[i], label=f'{year}ë…„')

        axes[1].set_xlabel('E9 ì²´ë¥˜ììˆ˜ (ëª…)')
        axes[1].set_ylabel('ê³ ìš©ë¥  (%)')
        axes[1].set_title('E9 ì²´ë¥˜ììˆ˜ vs ê³ ìš©ë¥  (ì—°ë„ë³„)')
        axes[1].legend()
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        plt.savefig(f"{self.output_dir}/scatter_analysis.png", dpi=300, bbox_inches='tight')
        plt.show()

        print(f"âœ… ì‚°ì ë„ ë¶„ì„ ì €ì¥: {self.output_dir}/scatter_analysis.png")

        # ìƒê´€ê³„ìˆ˜ ê³„ì‚°
        correlation = self.df['E9_ì²´ë¥˜ììˆ˜'].corr(self.df['ê³ ìš©ë¥ '])
        print(f"\nğŸ“Š ì „ì²´ ìƒê´€ê³„ìˆ˜: {correlation:.4f}")

        # ì—°ë„ë³„ ìƒê´€ê³„ìˆ˜
        print("\nğŸ“Š ì—°ë„ë³„ ìƒê´€ê³„ìˆ˜:")
        for year in sorted(self.df['ì—°ë„'].unique()):
            year_data = self.df[self.df['ì—°ë„'] == year]
            year_corr = year_data['E9_ì²´ë¥˜ììˆ˜'].corr(year_data['ê³ ìš©ë¥ '])
            print(f"   {year}ë…„: {year_corr:.4f}")

    def generate_policy_implications(self):
        """ì •ì±…ì  ì‹œì‚¬ì  ìƒì„±"""
        print("\n" + "="*50)
        print("ì •ì±…ì  ì‹œì‚¬ì  ë° ê²°ë¡ ")
        print("="*50)

        # íšŒê·€ë¶„ì„ ê²°ê³¼ì—ì„œ ì£¼ìš” ê³„ìˆ˜ ì¶”ì¶œ
        fe_results = self.results['fixed_effects']
        coef_df = fe_results['coefficients']

        e9_coef = coef_df[coef_df['Variable'] == 'E9_ì²´ë¥˜ììˆ˜']['Coefficient'].iloc[0]
        e9_pval = coef_df[coef_df['Variable'] == 'E9_ì²´ë¥˜ììˆ˜']['P_Value'].iloc[0]

        manufacturing_coef = coef_df[coef_df['Variable'] == 'ì œì¡°ì—…_ë¹„ì¤‘']['Coefficient'].iloc[0]
        manufacturing_pval = coef_df[coef_df['Variable'] == 'ì œì¡°ì—…_ë¹„ì¤‘']['P_Value'].iloc[0]

        covid_coef = coef_df[coef_df['Variable'] == 'COVID-19_ë”ë¯¸']['Coefficient'].iloc[0]
        covid_pval = coef_df[coef_df['Variable'] == 'COVID-19_ë”ë¯¸']['P_Value'].iloc[0]

        print("ğŸ’¡ ì£¼ìš” ë¶„ì„ ê²°ê³¼:")
        print("-" * 50)

        # E9 íš¨ê³¼
        sig_e9 = "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨" if e9_pval < 0.05 else "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ"
        effect_e9 = "ì–‘ì˜ íš¨ê³¼" if e9_coef > 0 else "ìŒì˜ íš¨ê³¼"
        print(f"1. E9 ì²´ë¥˜ììˆ˜ì˜ ê³ ìš©ë¥  íš¨ê³¼: {effect_e9} ({sig_e9})")
        print(f"   - ê³„ìˆ˜: {e9_coef:.4f} (p-value: {e9_pval:.4f})")
        if abs(e9_coef) > 0:
            print(f"   - í•´ì„: E9 ì²´ë¥˜ì 1ëª… ì¦ê°€ì‹œ ê³ ìš©ë¥  {e9_coef*1:.4f}%p ë³€í™”")

        # ì œì¡°ì—… íš¨ê³¼
        sig_mfg = "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨" if manufacturing_pval < 0.05 else "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ"
        effect_mfg = "ì–‘ì˜ íš¨ê³¼" if manufacturing_coef > 0 else "ìŒì˜ íš¨ê³¼"
        print(f"\n2. ì œì¡°ì—… ë¹„ì¤‘ì˜ ê³ ìš©ë¥  íš¨ê³¼: {effect_mfg} ({sig_mfg})")
        print(f"   - ê³„ìˆ˜: {manufacturing_coef:.4f} (p-value: {manufacturing_pval:.4f})")

        # COVID-19 íš¨ê³¼
        sig_covid = "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•¨" if covid_pval < 0.05 else "í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•˜ì§€ ì•ŠìŒ"
        effect_covid = "ì–‘ì˜ íš¨ê³¼" if covid_coef > 0 else "ìŒì˜ íš¨ê³¼"
        print(f"\n3. COVID-19ì˜ ê³ ìš©ë¥  íš¨ê³¼: {effect_covid} ({sig_covid})")
        print(f"   - ê³„ìˆ˜: {covid_coef:.4f} (p-value: {covid_pval:.4f})")

        # ì—°ë„ë³„ ì¶”ì„¸ ë¶„ì„
        if 'yearly_effects' in self.results:
            yearly_effects = self.results['yearly_effects']
            avg_yearly_effect = np.mean(list(yearly_effects.values()))
            print(f"\n4. ì—°ë„ë³„ E9-ê³ ìš©ë¥  ìƒê´€ê´€ê³„ í‰ê· : {avg_yearly_effect:.4f}")

        # ì§€ì—­ë³„ ë¹„êµ ë¶„ì„
        if 'regional_comparison' in self.results:
            regional_comp = self.results['regional_comparison']
            top_avg = regional_comp['top_regions']['ê³ ìš©ë¥ '].mean()
            bottom_avg = regional_comp['bottom_regions']['ê³ ìš©ë¥ '].mean()
            diff = top_avg - bottom_avg
            print(f"\n5. ì§€ì—­ë³„ ì°¨ì´ ë¶„ì„:")
            print(f"   - E9 ìƒìœ„ì§€ì—­ vs í•˜ìœ„ì§€ì—­ ê³ ìš©ë¥  ì°¨ì´: {diff:.2f}%p")

        print("\nğŸ’¡ ì •ì±…ì  ì‹œì‚¬ì :")
        print("-" * 50)

        if e9_pval < 0.05:
            if e9_coef > 0:
                print("1. E9 ë¹„ì ì œë„ì˜ ê¸ì •ì  íš¨ê³¼ í™•ì¸:")
                print("   - E9 ì²´ë¥˜ì ì¦ê°€ê°€ ì§€ì—­ ê³ ìš©ë¥  í–¥ìƒì— ê¸°ì—¬")
                print("   - ì™¸êµ­ì¸ë ¥ ì •ì±…ì˜ ì§€ì†ì  í™•ëŒ€ í•„ìš”ì„± ì‹œì‚¬")
                print("   - íŠ¹íˆ ì œì¡°ì—… ì¤‘ì‹¬ ì§€ì—­ì—ì„œ íš¨ê³¼ì ì¼ ê°€ëŠ¥ì„±")
            else:
                print("1. E9 ë¹„ì ì œë„ì˜ ë³µí•©ì  íš¨ê³¼:")
                print("   - ì§ì ‘ì  ëŒ€ì²´íš¨ê³¼ ê°€ëŠ¥ì„± ì‹œì‚¬")
                print("   - ì •ì±… ì„¤ê³„ ì‹œ ë³´ì™„ì  ì ‘ê·¼ í•„ìš”")
        else:
            print("1. E9 ë¹„ì ì œë„ì˜ ì¤‘ë¦½ì  íš¨ê³¼:")
            print("   - í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì§ì ‘íš¨ê³¼ ë¯¸ë°œê²¬")
            print("   - ì§€ì—­ë³„, ì‚°ì—…ë³„ ì´ì§ˆì  íš¨ê³¼ ê°€ëŠ¥ì„±")

        if manufacturing_pval < 0.05:
            if manufacturing_coef > 0:
                print("\n2. ì œì¡°ì—… ì¤‘ì‹¬ ì§€ì—­ì˜ ê³ ìš© ìš°ìœ„:")
                print("   - ì œì¡°ì—… ë¹„ì¤‘ì´ ë†’ì€ ì§€ì—­ì˜ ê³ ìš©ë¥  ìš°ì„¸")
                print("   - ì œì¡°ì—… ìœ¡ì„±ì •ì±…ê³¼ ì™¸êµ­ì¸ë ¥ ì •ì±… ì—°ê³„ íš¨ê³¼")
            else:
                print("\n2. ì„œë¹„ìŠ¤ì—… ì „í™˜ì˜ ê³ ìš© íš¨ê³¼:")
                print("   - ì„œë¹„ìŠ¤ì—… ì¤‘ì‹¬ìœ¼ë¡œì˜ ì‚°ì—…êµ¬ì¡° ë³€í™” ê¸ì •ì ")
                print("   - ì‚°ì—…ì „í™˜ê³¼ í•¨ê»˜ ì™¸êµ­ì¸ë ¥ ì •ì±… ì¬ì¡°ì • í•„ìš”")

        if covid_pval < 0.05:
            if covid_coef < 0:
                print("\n3. COVID-19 íŒ¬ë°ë¯¹ì˜ ê³ ìš© ì¶©ê²© í™•ì¸:")
                print("   - 2020ë…„ ì´í›„ êµ¬ì¡°ì  ê³ ìš©ë¥  í•˜ë½")
                print("   - í¬ìŠ¤íŠ¸ ì½”ë¡œë‚˜ ê³ ìš©íšŒë³µ ì •ì±… í•„ìš”")
                print("   - ì™¸êµ­ì¸ë ¥ ì •ì±…ë„ íŒ¬ë°ë¯¹ íš¨ê³¼ ë°˜ì˜í•œ ì¬ì„¤ê³„ í•„ìš”")

        print(f"\nğŸ“Š ëª¨ë¸ ì„¤ëª…ë ¥:")
        print(f"   - R-squared: {fe_results['r_squared']:.4f}")
        print(f"   - ëª¨ë¸ì´ ê³ ìš©ë¥  ë³€ë™ì˜ {fe_results['r_squared']*100:.1f}%ë¥¼ ì„¤ëª…")

        print("\nğŸ“ˆ ì •ì±… ì œì–¸:")
        print("-" * 30)
        if e9_coef > 0 and e9_pval < 0.05:
            print("1. ì™¸êµ­ì¸ë ¥ ì •ì±… í™•ëŒ€ ë°©ì•ˆ:")
            print("   - E9 ë¹„ì ì¿¼í„° ì ì§„ì  í™•ëŒ€")
            print("   - ì œì¡°ì—… ì§‘ì¤‘ ì§€ì—­ ìš°ì„  ë°°ì •")
            print("   - ê³ ìš©í—ˆê°€ì œ ê°œì„ ì„ í†µí•œ íš¨ìœ¨ì„± ì œê³ ")

        print("\n2. ì§€ì—­ë³„ ë§ì¶¤í˜• ì •ì±…:")
        print("   - ì œì¡°ì—… ë¹„ì¤‘ì— ë”°ë¥¸ ì°¨ë³„í™”ëœ ì ‘ê·¼")
        print("   - ê³ ìš©ë¥ ì´ ë‚®ì€ ì§€ì—­ì— ëŒ€í•œ ì§‘ì¤‘ ì§€ì›")
        print("   - ì‚°ì—…êµ¬ì¡° ì „í™˜ ì§€ì› í”„ë¡œê·¸ë¨")

        print("\n3. ëª¨ë‹ˆí„°ë§ ë° í‰ê°€ ì²´ê³„:")
        print("   - ì§€ì—­ë³„ ê³ ìš©íš¨ê³¼ ì •ê¸° í‰ê°€")
        print("   - COVID-19 ë“± ì™¸ë¶€ ì¶©ê²© ì˜í–¥ ë¶„ì„")
        print("   - ì •ì±… íš¨ê³¼ì„± ì§€ì† ëª¨ë‹ˆí„°ë§")

        print("\nâš ï¸ ë¶„ì„ì˜ í•œê³„ ë° í›„ì† ì—°êµ¬ ê³¼ì œ:")
        print("-" * 40)
        print("1. ë°©ë²•ë¡ ì  í•œê³„:")
        print("   - ì¸ê³¼ê´€ê³„ ì¶”ë¡ ì˜ í•œê³„ (ë‚´ìƒì„± ë¬¸ì œ)")
        print("   - ì„ íƒí¸ì˜ ë° ëˆ„ë½ë³€ìˆ˜ í¸ì˜ ê°€ëŠ¥ì„±")
        print("   - ë‹¨ê¸°ê°„(5ë…„) íŒ¨ë„ë°ì´í„°ì˜ í•œê³„")

        print("\n2. ë°ì´í„°ì˜ í•œê³„:")
        print("   - 153ê°œ ì‹œêµ°êµ¬ í•œì • (ì „êµ­ 230ê°œ ëŒ€ë¹„)")
        print("   - ì—…ì¢…ë³„ ì„¸ë¶„í™” ë¶€ì¡±")
        print("   - ì„ê¸ˆ, ìƒì‚°ì„± ë“± ì¶”ê°€ ë³€ìˆ˜ ë¶€ì¬")

        print("\n3. í›„ì† ì—°êµ¬ í•„ìš”:")
        print("   - ë„êµ¬ë³€ìˆ˜ë¥¼ í™œìš©í•œ ì¸ê³¼ì¶”ë¡ ")
        print("   - ì—…ì¢…ë³„, ê¸°ì—…ê·œëª¨ë³„ ì„¸ë¶„ ë¶„ì„")
        print("   - ì¥ê¸° íš¨ê³¼ ë¶„ì„ì„ ìœ„í•œ ì‹œê³„ì—´ í™•ì¥")
        print("   - ì§ˆì  ì—°êµ¬ë¥¼ í†µí•œ ë©”ì»¤ë‹ˆì¦˜ ê·œëª…")

    def run_full_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        setup_korean_font()

        if not self.load_data():
            return False

        self.create_panel_variables()

        if not self.fixed_effects_regression():
            return False

        self.create_correlation_matrix()
        self.create_trend_analysis()
        self.create_scatter_analysis()
        self.generate_policy_implications()

        print("\n" + "="*80)
        print("ğŸ‰ ì¢…í•© ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ íŒŒì¼ë“¤ì´ {self.output_dir}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print("="*80)

        return True

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    data_path = "/Users/kapr/Desktop/DataAnalyze/new_analysis/data/new_processed/comprehensive_integrated_data.csv"

    if not os.path.exists(data_path):
        print(f"âŒ ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        return

    analyzer = PanelDataAnalyzer(data_path)
    analyzer.run_full_analysis()

if __name__ == "__main__":
    main()